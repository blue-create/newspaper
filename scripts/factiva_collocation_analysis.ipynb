{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4f3e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a95749be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check working directory\n",
    "import os\n",
    "os.getcwd() # if directory is subfolder, change to home\n",
    "os.chdir('/home/sukayna/Documents/github/newspaper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "679ec6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import usual packages\n",
    "import json\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "import datetime as dt\n",
    "import locale\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e875237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# always use json to load the corpus\n",
    "with open('data/factiva_data.json', 'r') as f:\n",
    "    factiva_corpus = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420d4e8",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "\n",
    "### Main steps:\n",
    "\n",
    "- load (german) spacy model \n",
    "- convert corpus to spacy language object\n",
    "- run preprocessing function to clean corpus\n",
    "\n",
    "- review stopwords to keep causal language/verbs/pronouns\n",
    "\n",
    "- create two versions of corpus for comparison: \n",
    "    - fully cleaned w/o entities/stopwords/proper nouns\n",
    "    - partially cleaned w/o entities/proper nouns but w/causal stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a91da867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "spacy_mod = spacy.load(\"de_core_news_lg\",\n",
    "                 disable=['ner', 'parser', 'tagger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcda90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create smaller set of acceptable stopwords\n",
    "# remove verbs, pronouns and connectors with causal meaning from stopwords\n",
    "spacy_mod.Defaults.stop_words -= {'kam', 'sollte', 'dich', 'achte', 'daraus', 'dir', 'werdet', 'seid', 'unser', 'macht', 'deswegen',\n",
    "                                  'außerdem', 'damit', 'habe', 'können', 'könnt', 'hatte', 'werde', 'andere', 'deiner', 'meines',\n",
    "                                  'niemandem', 'achten', 'dürft', 'rechten', 'machte', 'dahinter', 'sah', 'seinen', 'dementsprechend',\n",
    "                                  'kann', 'muß', 'wäre', 'geworden', 'wegen', 'machen', 'waren', 'dürfen', 'dein', 'mögen', 'würde',\n",
    "                                  'musst', 'magst', 'ihren', 'aber', 'möchte', 'ihr', 'wir', 'allerdings', 'jedem', 'nicht', 'ihres',\n",
    "                                  'kommt', 'gibt', 'infolgedessen', 'mögt', 'doch', 'sollten', 'seine', 'keine', 'wollte', 'ich',\n",
    "                                  'müssen', 'wollten', 'warum', 'ist', 'ihnen', 'mein', 'mochte', 'geht', 'trotzdem', 'gab', 'durfte',\n",
    "                                  'dagegen', 'sie', 'sind', 'wart', 'wer', 'haben', 'du', 'werden', 'eigene', 'ihn', 'seien', 'eigen',\n",
    "                                  'meinen', 'seiner', 'hatten', 'müsst', 'wollen', 'indem', 'wollt', 'gehabt', 'deine',  'denn',\n",
    "                                  'nachdem', 'konnte', 'ihrer', 'seinem', 'gemusst', 'bin', 'währenddem', 'dank', 'willst', 'würden',\n",
    "                                  'gemocht',  'hätten', 'demzufolge', 'seines', 'mussten', 'nahm', 'daher', 'darauf', 'ging', 'mochten',\n",
    "                                  'meinem', 'darum', 'gedurft', 'wurden', 'bist', 'ihrem', 'gehen', 'sein', 'kannst', 'gewollt',\n",
    "                                  'könnte',  'heisst', 'neben', 'meiner', 'euch', 'darfst', 'deshalb', 'konnten', 'ausserdem', 'ihm',\n",
    "                                  'tun', 'gekannt',  'worden', 'habt', 'darf', 'demgegenüber', 'gewesen', 'sollen', 'soll', 'kommen',\n",
    "                                  'tat', 'jahre'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d94fbf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 2564/2564 [00:56<00:00, 45.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert corpus to language object\n",
    "factiva_spacy = []\n",
    "for doc in tqdm(factiva_corpus):\n",
    "    factiva_spacy.append(spacy_mod(doc['body']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1909af88",
   "metadata": {},
   "source": [
    "## Preprocessing the corpus\n",
    "\n",
    "- Cleaned the corpus: \n",
    "    - factiva_cleaned (removes edited stopwords and entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22db5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing\n",
    "def preprocess(doc: str, remove_ent=False):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        doc (str): String text\n",
    "        remove_ent (bool, optional): If True, removes entities using spaCy. Defaults to False.\n",
    "        remove_stop (bool, optional): If True, removes stopwords using adapted spaCy stopword list. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        doc_preprocessed (list): Preprocessed lower-case corpus with punctuation, non-alphanumeric characters, spaCy stopwords and proper nouns removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    if remove_ent == True:\n",
    "        doc_no_ent = []\n",
    "        ents = [e.text for e in doc.ents]\n",
    "        for item in doc:\n",
    "            if item.text in ents:\n",
    "                pass\n",
    "            else:\n",
    "                doc_no_ent.append(item)\n",
    "\n",
    "        doc_preprocessed = [token.lower_ for token in doc_no_ent if\n",
    "                            # token is not punctuation\n",
    "                            token.is_punct == False and\n",
    "                            # token is alphanumeric character\n",
    "                            token.is_alpha == True and\n",
    "                            # token is not stop word\n",
    "                            token.is_stop == False and\n",
    "                            # token is not proper noun\n",
    "                            token.pos_ != \"PROPN\"]\n",
    "        \n",
    "    else: # do not remove entities\n",
    "        doc_preprocessed = [token.lower_ for token in doc if\n",
    "                            # token is not punctuation\n",
    "                            token.is_punct == False and\n",
    "                            # token is alphanumeric character\n",
    "                            token.is_alpha == True and\n",
    "                            # token is not stop word\n",
    "                            token.is_stop == False and\n",
    "                            # token is not proper noun\n",
    "                            token.pos_ != \"PROPN\"]\n",
    "\n",
    "    return doc_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7542c1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 2564/2564 [00:00<00:00, 3035.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocess:remove stopwords\n",
    "factiva_cleaned = []\n",
    "for doc in tqdm(factiva_spacy): \n",
    "    factiva_cleaned.append(preprocess(doc, remove_ent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30460041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mit stark blutenden stich- und schnittverletzungen ist ein 29 jahre alter mann auf einem gehweg in berlin-schöneberg gefunden worden. ein passant rief am dienstagabend nach 23.00 uhr\n",
      "145\n",
      "['stark', 'blutenden', 'schnittverletzungen', 'ist', 'jahre', 'alter', 'mann', 'gehweg', 'gefunden', 'worden']\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# compare dirty and cleaned corpus\n",
    "print(factiva_spacy[5][0:30], len(factiva_spacy[5]), sep='\\n')\n",
    "print(factiva_cleaned[5][0:10], len(factiva_cleaned[5]), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c727b",
   "metadata": {},
   "source": [
    "# Collocation Analysis\n",
    "\n",
    "## Main steps:\n",
    "\n",
    "- Create bi/tri/quad- ngrams\n",
    "- Rank order ngrams by raw frequency (print to txt files)\n",
    "\n",
    "- Examine association measures for top 50 ngrams\n",
    "- Analyse differences in ngrams across documents\n",
    "- Check for collocation strength/significance testing\n",
    "\n",
    "- plot comparisons: association strength (dot chart) / network graphs / biplots (using semantic similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba52c3",
   "metadata": {},
   "source": [
    "## 1) Creating & Ranking Ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c16f7d",
   "metadata": {},
   "source": [
    "- Bigrams from cleaned and unprocessed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c183d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank bigrams by given metric \n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics.association import BigramAssocMeasures\n",
    "\n",
    "def rank_bigrams(corpus, metric, from_words=False, threshold=int, path=None):\n",
    "    \"\"\"\n",
    "    Find and rank ngrams from the supplied corpus using the given\n",
    "    association metric. Write the trigrams out to the given path if\n",
    "    supplied otherwise return the list in memory.\n",
    "    \n",
    "    Args:\n",
    "    from_words (bool, optional): If True, unlist all documents and create ngrams from words.\n",
    "    threshold (int): ignore all ngrams which occur less than n times in the corpus\n",
    "    path (str): path to save ngram list as .txt file\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if from_words == True:\n",
    "        #turn all doc tokens into one single list\n",
    "        unlist_corpus = [item for items in corpus for item in items]\n",
    "        # Create a collocation ranking utility from corpus\n",
    "        finder = BigramCollocationFinder.from_words(unlist_corpus)\n",
    "        # Apply frequency filter = at least 3 times\n",
    "        finder.apply_freq_filter(threshold)\n",
    "        # Rank collocations by an association metric\n",
    "        scored = finder.score_ngrams(metric)\n",
    "            \n",
    "    else: \n",
    "        finder = BigramCollocationFinder.from_documents(corpus)\n",
    "        finder.apply_freq_filter(threshold)\n",
    "        scored = finder.score_ngrams(metric)\n",
    "\n",
    "    if path:\n",
    "    # Write to disk as tab-delimited file\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(\"Collocation\\tScore ({})\\n\".format(metric.__name__))\n",
    "            for ngram, score in scored:\n",
    "                f.write(\"{}\\t{}\\n\".format(repr(ngram), score))\n",
    "    else:\n",
    "        return scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3c4072f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_freq + minimum 3 occurences + from_words\n",
    "rank_bigrams(factiva_cleaned, BigramAssocMeasures.raw_freq, from_words=True, threshold=3, path='outputs/factiva_bigrams_from_words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a233fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT RUN - rank_* function can be used to output all available measures for ngram comparison\n",
    "\n",
    "# rank_bigrams(factiva_cleaned, BigramAssocMeasures.pmi,\n",
    "#              'outputs/factiva_bigrams_pmi.txt')\n",
    "# rank_bigrams(factiva_cleaned, BigramAssocMeasures.chi_sq,\n",
    "#              'outputs/factiva_bigrams_chisq.txt')\n",
    "# rank_bigrams(factiva_cleaned, BigramAssocMeasures.student_t,\n",
    "#              'outputs/factiva_bigrams_ttest.txt')\n",
    "# rank_bigrams(factiva_cleaned, BigramAssocMeasures.likelihood_ratio,\n",
    "#              'outputs/factiva_bigrams_likelihood.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e78d753",
   "metadata": {},
   "source": [
    "- Trigrams from cleaned and unprocessed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1955b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics.association import TrigramAssocMeasures\n",
    "\n",
    "def rank_trigrams(corpus, metric, from_words=False, threshold=int, path=None):\n",
    "    \"\"\"\n",
    "    Find and rank ngrams from the supplied corpus using the given\n",
    "    association metric. Write the trigrams out to the given path if\n",
    "    supplied otherwise return the list in memory.\n",
    "    \n",
    "    Args:\n",
    "    from_words (bool, optional): If True, unlist all documents and create ngrams from words.\n",
    "    threshold (int): ignore all ngrams which occur less than n times in the corpus\n",
    "    path (str): path to save ngram list as .txt file\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if from_words == True:\n",
    "        #turn all doc tokens into one single list\n",
    "        unlist_corpus = [item for items in corpus for item in items]\n",
    "        # Create a collocation ranking utility from corpus\n",
    "        finder = TrigramCollocationFinder.from_words(unlist_corpus)\n",
    "        # Apply frequency filter = at least 3 times\n",
    "        finder.apply_freq_filter(threshold)\n",
    "        # Rank collocations by an association metric\n",
    "        scored = finder.score_ngrams(metric)\n",
    "            \n",
    "    else: \n",
    "        finder = TrigramCollocationFinder.from_documents(corpus)\n",
    "        finder.apply_freq_filter(threshold)\n",
    "        scored = finder.score_ngrams(metric)\n",
    "\n",
    "    if path:\n",
    "    # Write to disk as tab-delimited file\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(\"Collocation\\tScore ({})\\n\".format(metric.__name__))\n",
    "            for ngram, score in scored:\n",
    "                f.write(\"{}\\t{}\\n\".format(repr(ngram), score))\n",
    "    else:\n",
    "        return scored\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ecc6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cleaned factiva corpus\n",
    "rank_trigrams(factiva_cleaned, TrigramAssocMeasures.raw_freq, from_words=True, threshold=3, path='outputs/factiva_trigrams_from_words.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d7763",
   "metadata": {},
   "source": [
    "- Quadgrams from cleaned and unprocessed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "be315071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank quadgrams by given metric \n",
    "from nltk.collocations import QuadgramCollocationFinder\n",
    "from nltk.metrics.association import QuadgramAssocMeasures\n",
    "\n",
    "def rank_quadgrams(corpus, metric, from_words=False, threshold=int, path=None):\n",
    "    \"\"\"\n",
    "    Find and rank ngrams from the supplied corpus using the given\n",
    "    association metric. Write the trigrams out to the given path if\n",
    "    supplied otherwise return the list in memory.\n",
    "    \n",
    "    Args:\n",
    "    from_words (bool, optional): If True, unlist all documents and create ngrams from words.\n",
    "    threshold (int): ignore all ngrams which occur less than n times in the corpus\n",
    "    path (str): path to save ngram list as .txt file\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if from_words == True:\n",
    "        #turn all doc tokens into one single list\n",
    "        unlist_corpus = [item for items in corpus for item in items]\n",
    "        # Create a collocation ranking utility from corpus\n",
    "        finder = QuadgramCollocationFinder.from_words(unlist_corpus)\n",
    "        # Apply frequency filter = at least 3 times\n",
    "        finder.apply_freq_filter(threshold)\n",
    "        # Rank collocations by an association metric\n",
    "        scored = finder.score_ngrams(metric)\n",
    "            \n",
    "    else: \n",
    "        finder = QuadgramCollocationFinder.from_documents(corpus)\n",
    "        finder.apply_freq_filter(threshold)\n",
    "        scored = finder.score_ngrams(metric)\n",
    "\n",
    "    if path:\n",
    "    # Write to disk as tab-delimited file\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(\"Collocation\\tScore ({})\\n\".format(metric.__name__))\n",
    "            for ngram, score in scored:\n",
    "                f.write(\"{}\\t{}\\n\".format(repr(ngram), score))\n",
    "    else:\n",
    "        return scored\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2e2d5e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cleaned factiva corpus\n",
    "rank_quadgrams(factiva_cleaned, QuadgramAssocMeasures.raw_freq, from_words=True, threshold=3, path='outputs/factiva_quadgrams_from_docs.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5974024",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "\n",
    "**Observations in the trigrams**\n",
    "\n",
    "Overall general observations:\n",
    "- Among the 42 most frequent trigrams, 20 contain the bigram “häusliche[r] gewalt”, which shows the importance of this bigram in the sub-corpus construction by Factiva.\n",
    "    => results in a majority of articles that talk more generally about the phenomenon and less frequently about actual cases\n",
    "- A lot of trigrams contain “gewalt”, which underlines the strong importance of this term for subcorpus construction\n",
    "    => suggests that there might be a lack of recall for articles without “Gewalt”\n",
    "\n",
    "General observations:\n",
    "- “Fälle [von]” = providing context\n",
    "- “insgesamt” or “Zahl [der Fälle]” = Statistik\n",
    "- Plural (“Väter | Ehemänner | etc.] = providing context above individual cases (note: “partner” = singular and plural)\n",
    "- Verbs in Singular (“starb”, “stirbt”) are a strong marker of individual cases\n",
    "- Description of age (“-jährige”, “Jahre alte”) can be markers of individual cases\n",
    "- “Prügel” or “verprügelt” seem to be strong markers of individual cases (not used as much in description of statistics or general situations)\n",
    "\n",
    "Interesting trigrams:\n",
    "- “sechsmonatigen kontaktverbot verurteilt” => very concrete situation\n",
    "- “beamten sprachen annäherungsverbot” =>\n",
    "- “blauen flecken gesicht” => case description\n",
    "- “grün blau geschlagen” => case description\n",
    "- “getrennt lebende Frau” => singular case\n",
    "- “mann\tvorläufig festgenommen” => police reporting\n",
    "- “mutmaßliche täter festgenommen” => police reporting\n",
    "- “psychisch druck gesetzt” => may be general or specific\n",
    "- “erlag verletzungen krankenhaus” => police reporting\n",
    "- “mutter erlag verletzungen” => police reporting\n",
    "- “faust gesicht geschlagen” => police or justice reporting in a singular case\n",
    "- “gemeinsame wohnung verlassen” => descriptives of a single case story\n",
    "- “antrag opfers angeordnet” => indicates agency of the victim\n",
    "\n",
    "Some relevant bigrams in the list:\n",
    "- “gewaltbetroffen[xx] [Person[xx] | Frau[xx]” <= adjective for victim of violence \n",
    "- vs “gewalttätig[xx] [Mann[xx] | Partner | Vater etc.] <= adjective perpetrator of violence\n",
    "- “seine [Ehe]Frau” “seine Partnerin” “seine Lebensgefährtin” + violence terms = hint for reporting on individual cases, with clear reference to the perpetrator being intimately linked\n",
    "    => NOTE: “seine” is not included in bi- and trigrams because it is removed as frequent word, but important marker for individual case description\n",
    "- “einstweilige verfügung” => singular case, police reporting\n",
    "- “krankenhaus gebracht” => rather singluar case\n",
    "- “name geändert” => annonymising victim or perpetrator\n",
    "- “polizei mitteilte” => police reporting\n",
    "- “ehefrau geschlagen” => violence in the marriage\n",
    "- “Johnny Depp” “Amber Heard”\n",
    "\n",
    "Interesting unigrams:\n",
    "- “Gewaltopfer” vs “Gewalttäter” => german words for victim and perpetrator of violence\n",
    "- “Beziehungsgewalt” => not domestic but relationship violence\n",
    "- “Partnerschaft” vs “Beziehung” => check for these synonyms\n",
    "- “mutmaßlich[xx]” => police reporting\n",
    "\n",
    "Observations of what is missing in the trigrams:\n",
    "- The elimination of the frequent words erases typical trigrams such as “Gewalt gegen Frauen”\n",
    "    => question to what degree stopword removal deletes relevant markers\n",
    "\n",
    "Other observations:\n",
    "- There are certain ways of formulating general statements vs. formulating descriptions of single cases (e.g. temporal description-verb-subject: vs. subject-verb-temporal description)\n",
    "- “Fast an jedem dritten Tag im Jahr stirbt eine Frau durch Ex-Partner oder Partner…” (general reporting)\n",
    "    vs.\n",
    "- “Das Opfer starb am nächsten Tag.” (invented, case reporting)\n",
    "    vs.\n",
    "- “Die Opfer sterben häufig…” (invented, general reporting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a529f",
   "metadata": {},
   "source": [
    "### Comparison of association measures for ngrams\n",
    "\n",
    "- Create bigrams, trigrams and quadgram association measures: top frequency, pmi, t-test, chi-square, likelihood ratio test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e18e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_comparison(corpus, ngram=['bigram', 'trigram', 'quadgram'], threshold=int, top=int, path=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create comparison table for given ngram-type for \n",
    "    NLTK association measures based on supplied corpus.\n",
    "    \n",
    "    Specify how many top ranking ngrams should be compared. \n",
    "    \n",
    "    Write the ngram table out to the given path if \n",
    "    supplied otherwise return the table in memory.\n",
    "    \n",
    "    Args:\n",
    "    corpus (str): corpus that you want to examine\n",
    "    ngram (str): type of ngram (only one option per function run)\n",
    "    threshold (int): ignore all ngrams which occur less than n times in the corpus\n",
    "    top (int): number of top ngrams to be displayed\n",
    "    path (str): path to save ngram list as .txt file\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    unlist_corpus = [item for items in corpus for item in items]    \n",
    "    \n",
    "    if ngram == 'bigram':\n",
    "        Finder = nltk.collocations.BigramCollocationFinder.from_words(unlist_corpus)\n",
    "        metric = nltk.collocations.BigramAssocMeasures()\n",
    "        Finder.apply_freq_filter(threshold)\n",
    "    \n",
    "    if ngram == 'trigram':\n",
    "        Finder = nltk.collocations.TrigramCollocationFinder.from_words(unlist_corpus)\n",
    "        metric = nltk.collocations.TrigramAssocMeasures()\n",
    "        Finder.apply_freq_filter(threshold)\n",
    "        \n",
    "    if ngram == 'quadgram':\n",
    "        Finder = nltk.collocations.QuadgramCollocationFinder.from_words(unlist_corpus)\n",
    "        metric = nltk.collocations.QuadgramAssocMeasures()\n",
    "        Finder.apply_freq_filter(threshold)\n",
    "\n",
    "    try:        \n",
    "        freq_top = pd.DataFrame(list(Finder.score_ngrams(metric.raw_freq)), \n",
    "                              columns=['ngram','freq']).sort_values(by='freq', ascending=False)[:top].ngram.values\n",
    "        \n",
    "        pmi_top = pd.DataFrame(list(Finder.score_ngrams(metric.pmi)), \n",
    "                             columns=['ngram','pmi']).sort_values(by='pmi', ascending=False)[:top].ngram.values\n",
    "       \n",
    "        ttest_top = pd.DataFrame(list(Finder.score_ngrams(metric.student_t)), \n",
    "                             columns=['ngram','t-test']).sort_values(by='t-test', ascending=False)[:top].ngram.values\n",
    "       \n",
    "        chisq_top = pd.DataFrame(list(Finder.score_ngrams(metric.chi_sq)), \n",
    "                             columns=['ngram','chisq']).sort_values(by='chisq', ascending=False)[:top].ngram.values\n",
    "       \n",
    "        lrt_top = pd.DataFrame(list(Finder.score_ngrams(metric.likelihood_ratio)), \n",
    "                             columns=['ngram','lrt']).sort_values(by='lrt', ascending=False)[:top].ngram.values\n",
    "        \n",
    "    finally: \n",
    "        ngram_comparison = pd.DataFrame([freq_top, pmi_top, ttest_top, chisq_top, lrt_top]).T\n",
    "        ngram_comparison.columns = ['Frequency', 'PMI', 'T-Test', 'Chi-Square', 'Likelihood Ratio']\n",
    "    \n",
    "    if path:\n",
    "        with open(path, 'w') as f:\n",
    "            ngram_comparison.to_csv(f, sep='\\t', index = False)\n",
    "            \n",
    "    else: \n",
    "        return ngram_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d18233c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare assoc measures for bigrams\n",
    "ngram_comparison(factiva_cleaned, ngram = 'bigram', threshold=3, top=50, path='outputs/cleaned_bigrams_assoc_measures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fb36ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare assoc measures for trigrams\n",
    "ngram_comparison(factiva_cleaned, ngram = 'trigram', threshold=3, top = 50, path='outputs/cleaned_trigrams_assoc_measures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f9979cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare assoc measures for quadgrams\n",
    "ngram_comparison(factiva_cleaned, ngram = 'quadgram', threshold=3, top = 50, path='outputs/cleaned_quadgrams_assoc_measures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9a0a4c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>PMI</th>\n",
       "      <th>T-Test</th>\n",
       "      <th>Chi-Square</th>\n",
       "      <th>Likelihood Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(verhütung, bekämpfung, gewalt, frauen)</td>\n",
       "      <td>(schichten, nationen, familienverhältnissen, b...</td>\n",
       "      <td>(verhütung, bekämpfung, gewalt, frauen)</td>\n",
       "      <td>(schichten, nationen, familienverhältnissen, b...</td>\n",
       "      <td>(häuslicher, gewalt, frauen, kinder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(gewalt, frauen, häuslicher, gewalt)</td>\n",
       "      <td>(deutsche, fassung, enw, bda)</td>\n",
       "      <td>(gewalt, frauen, häuslicher, gewalt)</td>\n",
       "      <td>(autor, deutsche, fassung, enw)</td>\n",
       "      <td>(fälle, häuslicher, gewalt, frauen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(bekämpfung, gewalt, frauen, häuslicher)</td>\n",
       "      <td>(autor, deutsche, fassung, enw)</td>\n",
       "      <td>(bekämpfung, gewalt, frauen, häuslicher)</td>\n",
       "      <td>(deutsche, fassung, enw, bda)</td>\n",
       "      <td>(häuslicher, gewalt, gewalt, frauen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(verein, frauen, helfen, frauen)</td>\n",
       "      <td>(veröffentlichung, bestimmt, kontakte, autor)</td>\n",
       "      <td>(verein, frauen, helfen, frauen)</td>\n",
       "      <td>(veröffentlichung, bestimmt, kontakte, autor)</td>\n",
       "      <td>(gewalt, frauen, häuslicher, gewalt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(europarats, verhütung, bekämpfung, gewalt)</td>\n",
       "      <td>(deutsche, fassung, redaktion, enw)</td>\n",
       "      <td>(europarats, verhütung, bekämpfung, gewalt)</td>\n",
       "      <td>(veröffentlichung, bestimmt, kontakte, autorin)</td>\n",
       "      <td>(opfer, häuslicher, gewalt, geworden)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(folgenden, informationen, sind, nicht)</td>\n",
       "      <td>(besetzt, landeskriminalamt, kriminalpräventio...</td>\n",
       "      <td>(nicht, veröffentlichung, bestimmt, kontakte)</td>\n",
       "      <td>(kontakte, autor, deutsche, fassung)</td>\n",
       "      <td>(zahl, opfer, häuslicher, gewalt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(informationen, sind, nicht, veröffentlichung)</td>\n",
       "      <td>(kontakte, autor, deutsche, fassung)</td>\n",
       "      <td>(sind, nicht, veröffentlichung, bestimmt)</td>\n",
       "      <td>(deutsche, fassung, redaktion, enw)</td>\n",
       "      <td>(prozent, opfer, häuslicher, gewalt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(nicht, veröffentlichung, bestimmt, kontakte)</td>\n",
       "      <td>(veröffentlichung, bestimmt, kontakte, autorin)</td>\n",
       "      <td>(folgenden, informationen, sind, nicht)</td>\n",
       "      <td>(übereinkommen, europarats, verhütung, bekämpf...</td>\n",
       "      <td>(männliche, opfer, häuslicher, gewalt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(sind, nicht, veröffentlichung, bestimmt)</td>\n",
       "      <td>(suchstichwörter, text, folgenden, informationen)</td>\n",
       "      <td>(informationen, sind, nicht, veröffentlichung)</td>\n",
       "      <td>(bestimmt, kontakte, autor, deutsche)</td>\n",
       "      <td>(opfer, häuslicher, gewalt, schützen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(häuslicher, gewalt, betroffen, sind)</td>\n",
       "      <td>(landeskriminalamt, kriminalprävention, bietet...</td>\n",
       "      <td>(häuslicher, gewalt, betroffen, sind)</td>\n",
       "      <td>(landeskriminalamt, kriminalprävention, bietet...</td>\n",
       "      <td>(schutz, opfer, häuslicher, gewalt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(opfer, häuslicher, gewalt, geworden)</td>\n",
       "      <td>(sozialen, schichten, nationen, familienverhäl...</td>\n",
       "      <td>(opfer, häuslicher, gewalt, geworden)</td>\n",
       "      <td>(besetzt, landeskriminalamt, kriminalpräventio...</td>\n",
       "      <td>(frauen, opfer, häuslicher, gewalt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(übereinkommen, europarats, verhütung, bekämpf...</td>\n",
       "      <td>(bestimmt, kontakte, autor, deutsche)</td>\n",
       "      <td>(übereinkommen, europarats, verhütung, bekämpf...</td>\n",
       "      <td>(suchstichwörter, text, folgenden, informationen)</td>\n",
       "      <td>(opfer, häuslicher, gewalt, wurden)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(einsatz, wegen, häuslicher, gewalt)</td>\n",
       "      <td>(autorin, deutsche, fassung, redaktion)</td>\n",
       "      <td>(einsatz, wegen, häuslicher, gewalt)</td>\n",
       "      <td>(autorin, deutsche, fassung, redaktion)</td>\n",
       "      <td>(opfer, häuslicher, gewalt, werden)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(frauen, opfer, häuslicher, gewalt)</td>\n",
       "      <td>(übereinkommen, europarats, verhütung, bekämpf...</td>\n",
       "      <td>(frauen, opfer, häuslicher, gewalt)</td>\n",
       "      <td>(sozialen, schichten, nationen, familienverhäl...</td>\n",
       "      <td>(opfer, häuslicher, gewalt, sind)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(opfer, häuslicher, gewalt, werden)</td>\n",
       "      <td>(kontakte, autorin, deutsche, fassung)</td>\n",
       "      <td>(opfer, häuslicher, gewalt, werden)</td>\n",
       "      <td>(kontakte, autorin, deutsche, fassung)</td>\n",
       "      <td>(opfer, häuslicher, gewalt, ist)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(gewalt, kommt, nicht, tüte)</td>\n",
       "      <td>(kriminalprävention, bietet, zusätzlich, berat...</td>\n",
       "      <td>(gewalt, kommt, nicht, tüte)</td>\n",
       "      <td>(kriminalprävention, bietet, zusätzlich, berat...</td>\n",
       "      <td>(männer, opfer, häuslicher, gewalt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(gewalt, frauen, häusliche, gewalt)</td>\n",
       "      <td>(bestimmt, kontakte, autorin, deutsche)</td>\n",
       "      <td>(gewalt, frauen, häusliche, gewalt)</td>\n",
       "      <td>(bestimmt, kontakte, autorin, deutsche)</td>\n",
       "      <td>(häufiger, opfer, häuslicher, gewalt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(anzeigen, wegen, häuslicher, gewalt)</td>\n",
       "      <td>(erreichbar, frauennotruf, vereins, wiener)</td>\n",
       "      <td>(anzeigen, wegen, häuslicher, gewalt)</td>\n",
       "      <td>(prügel, gewöhnliche, geschichte, häuslicher)</td>\n",
       "      <td>(menschen, opfer, häuslicher, gewalt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(zahl, fälle, häuslicher, gewalt)</td>\n",
       "      <td>(prügel, gewöhnliche, geschichte, häuslicher)</td>\n",
       "      <td>(zahl, fälle, häuslicher, gewalt)</td>\n",
       "      <td>(erreichbar, frauennotruf, vereins, wiener)</td>\n",
       "      <td>(opfer, häuslicher, gewalt, männer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(häuslicher, gewalt, geworden, sind)</td>\n",
       "      <td>(bietet, zusätzlich, beratungen, hotline)</td>\n",
       "      <td>(häuslicher, gewalt, geworden, sind)</td>\n",
       "      <td>(nicht, veröffentlichung, bestimmt, kontakte)</td>\n",
       "      <td>(sollen, opfer, häuslicher, gewalt)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Frequency  \\\n",
       "0             (verhütung, bekämpfung, gewalt, frauen)   \n",
       "1                (gewalt, frauen, häuslicher, gewalt)   \n",
       "2            (bekämpfung, gewalt, frauen, häuslicher)   \n",
       "3                    (verein, frauen, helfen, frauen)   \n",
       "4         (europarats, verhütung, bekämpfung, gewalt)   \n",
       "5             (folgenden, informationen, sind, nicht)   \n",
       "6      (informationen, sind, nicht, veröffentlichung)   \n",
       "7       (nicht, veröffentlichung, bestimmt, kontakte)   \n",
       "8           (sind, nicht, veröffentlichung, bestimmt)   \n",
       "9               (häuslicher, gewalt, betroffen, sind)   \n",
       "10              (opfer, häuslicher, gewalt, geworden)   \n",
       "11  (übereinkommen, europarats, verhütung, bekämpf...   \n",
       "12               (einsatz, wegen, häuslicher, gewalt)   \n",
       "13                (frauen, opfer, häuslicher, gewalt)   \n",
       "14                (opfer, häuslicher, gewalt, werden)   \n",
       "15                       (gewalt, kommt, nicht, tüte)   \n",
       "16                (gewalt, frauen, häusliche, gewalt)   \n",
       "17              (anzeigen, wegen, häuslicher, gewalt)   \n",
       "18                  (zahl, fälle, häuslicher, gewalt)   \n",
       "19               (häuslicher, gewalt, geworden, sind)   \n",
       "\n",
       "                                                  PMI  \\\n",
       "0   (schichten, nationen, familienverhältnissen, b...   \n",
       "1                       (deutsche, fassung, enw, bda)   \n",
       "2                     (autor, deutsche, fassung, enw)   \n",
       "3       (veröffentlichung, bestimmt, kontakte, autor)   \n",
       "4                 (deutsche, fassung, redaktion, enw)   \n",
       "5   (besetzt, landeskriminalamt, kriminalpräventio...   \n",
       "6                (kontakte, autor, deutsche, fassung)   \n",
       "7     (veröffentlichung, bestimmt, kontakte, autorin)   \n",
       "8   (suchstichwörter, text, folgenden, informationen)   \n",
       "9   (landeskriminalamt, kriminalprävention, bietet...   \n",
       "10  (sozialen, schichten, nationen, familienverhäl...   \n",
       "11              (bestimmt, kontakte, autor, deutsche)   \n",
       "12            (autorin, deutsche, fassung, redaktion)   \n",
       "13  (übereinkommen, europarats, verhütung, bekämpf...   \n",
       "14             (kontakte, autorin, deutsche, fassung)   \n",
       "15  (kriminalprävention, bietet, zusätzlich, berat...   \n",
       "16            (bestimmt, kontakte, autorin, deutsche)   \n",
       "17        (erreichbar, frauennotruf, vereins, wiener)   \n",
       "18      (prügel, gewöhnliche, geschichte, häuslicher)   \n",
       "19          (bietet, zusätzlich, beratungen, hotline)   \n",
       "\n",
       "                                               T-Test  \\\n",
       "0             (verhütung, bekämpfung, gewalt, frauen)   \n",
       "1                (gewalt, frauen, häuslicher, gewalt)   \n",
       "2            (bekämpfung, gewalt, frauen, häuslicher)   \n",
       "3                    (verein, frauen, helfen, frauen)   \n",
       "4         (europarats, verhütung, bekämpfung, gewalt)   \n",
       "5       (nicht, veröffentlichung, bestimmt, kontakte)   \n",
       "6           (sind, nicht, veröffentlichung, bestimmt)   \n",
       "7             (folgenden, informationen, sind, nicht)   \n",
       "8      (informationen, sind, nicht, veröffentlichung)   \n",
       "9               (häuslicher, gewalt, betroffen, sind)   \n",
       "10              (opfer, häuslicher, gewalt, geworden)   \n",
       "11  (übereinkommen, europarats, verhütung, bekämpf...   \n",
       "12               (einsatz, wegen, häuslicher, gewalt)   \n",
       "13                (frauen, opfer, häuslicher, gewalt)   \n",
       "14                (opfer, häuslicher, gewalt, werden)   \n",
       "15                       (gewalt, kommt, nicht, tüte)   \n",
       "16                (gewalt, frauen, häusliche, gewalt)   \n",
       "17              (anzeigen, wegen, häuslicher, gewalt)   \n",
       "18                  (zahl, fälle, häuslicher, gewalt)   \n",
       "19               (häuslicher, gewalt, geworden, sind)   \n",
       "\n",
       "                                           Chi-Square  \\\n",
       "0   (schichten, nationen, familienverhältnissen, b...   \n",
       "1                     (autor, deutsche, fassung, enw)   \n",
       "2                       (deutsche, fassung, enw, bda)   \n",
       "3       (veröffentlichung, bestimmt, kontakte, autor)   \n",
       "4     (veröffentlichung, bestimmt, kontakte, autorin)   \n",
       "5                (kontakte, autor, deutsche, fassung)   \n",
       "6                 (deutsche, fassung, redaktion, enw)   \n",
       "7   (übereinkommen, europarats, verhütung, bekämpf...   \n",
       "8               (bestimmt, kontakte, autor, deutsche)   \n",
       "9   (landeskriminalamt, kriminalprävention, bietet...   \n",
       "10  (besetzt, landeskriminalamt, kriminalpräventio...   \n",
       "11  (suchstichwörter, text, folgenden, informationen)   \n",
       "12            (autorin, deutsche, fassung, redaktion)   \n",
       "13  (sozialen, schichten, nationen, familienverhäl...   \n",
       "14             (kontakte, autorin, deutsche, fassung)   \n",
       "15  (kriminalprävention, bietet, zusätzlich, berat...   \n",
       "16            (bestimmt, kontakte, autorin, deutsche)   \n",
       "17      (prügel, gewöhnliche, geschichte, häuslicher)   \n",
       "18        (erreichbar, frauennotruf, vereins, wiener)   \n",
       "19      (nicht, veröffentlichung, bestimmt, kontakte)   \n",
       "\n",
       "                          Likelihood Ratio  \n",
       "0     (häuslicher, gewalt, frauen, kinder)  \n",
       "1      (fälle, häuslicher, gewalt, frauen)  \n",
       "2     (häuslicher, gewalt, gewalt, frauen)  \n",
       "3     (gewalt, frauen, häuslicher, gewalt)  \n",
       "4    (opfer, häuslicher, gewalt, geworden)  \n",
       "5        (zahl, opfer, häuslicher, gewalt)  \n",
       "6     (prozent, opfer, häuslicher, gewalt)  \n",
       "7   (männliche, opfer, häuslicher, gewalt)  \n",
       "8    (opfer, häuslicher, gewalt, schützen)  \n",
       "9      (schutz, opfer, häuslicher, gewalt)  \n",
       "10     (frauen, opfer, häuslicher, gewalt)  \n",
       "11     (opfer, häuslicher, gewalt, wurden)  \n",
       "12     (opfer, häuslicher, gewalt, werden)  \n",
       "13       (opfer, häuslicher, gewalt, sind)  \n",
       "14        (opfer, häuslicher, gewalt, ist)  \n",
       "15     (männer, opfer, häuslicher, gewalt)  \n",
       "16   (häufiger, opfer, häuslicher, gewalt)  \n",
       "17   (menschen, opfer, häuslicher, gewalt)  \n",
       "18     (opfer, häuslicher, gewalt, männer)  \n",
       "19     (sollen, opfer, häuslicher, gewalt)  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualise comparison tabel for quadgrams \n",
    "ngram_comparison(factiva_cleaned, ngram = 'quadgram', threshold=8, top = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e324a0",
   "metadata": {},
   "source": [
    "#### END OF CODE "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frontline",
   "language": "python",
   "name": "frontline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
