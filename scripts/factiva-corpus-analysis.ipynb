{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start\n",
    "\n",
    "- Set working directory\n",
    "- Load modules\n",
    "- Load data\n",
    "- Set datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check working directory\n",
    "import os\n",
    "os.getcwd() # if directory is subfolder, change to home\n",
    "os.chdir('/Users/nhuquynh/Documents/Frontline/newspaper/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhuquynh/Library/Python/3.8/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "import datetime as dt\n",
    "import locale\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('data/factiva_data.json', 'r') as f:\n",
    "    factiva_corpus = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de_DE.UTF-8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change date format\n",
    "locale.setlocale(locale.LC_ALL, 'de_DE.UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing \n",
    "\n",
    "- Convert time data to datetime format \n",
    "- Load spaCy model for tokenization and preprocessing\n",
    "- Remove punctuation, symbols and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string dates to datetime format\n",
    "# Year-Month-Day HH:MM:SS is the default output for string dates\n",
    "\n",
    "for doc in factiva_corpus: \n",
    "    doc['date'] = dt.datetime.strptime(doc['date'], '%d %B %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2564/2564 [01:38<00:00, 26.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "spacy_mod = spacy.load('de_core_news_lg',\n",
    "                 disable=['ner', 'parser', 'tagger'])\n",
    "\n",
    "# Turn to Language object\n",
    "factiva_spacy = []\n",
    "for doc in tqdm(factiva_corpus):\n",
    "    factiva_spacy.append(spacy_mod(doc['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'früher', 'drei', 'großer', 'siebenten', 'sondern', 'über', 'bald', 'dasein', 'heute', 'kleine', 'wenigstens', 'einem', 'aller', 'zwar', 'neue', 'gekonnt', 'allgemeinen', 'vom', 'zwischen', 'derselbe', 'gern', 'jedoch', 'tage', 'wird', 'damals', 'solchen', 'zehn', 'manches', 'siebenter', 'offen', 'siebter', 'ihre', 'wem', 'geschweige', 'denen', 'groß', 'an', 'keinem', 'derjenige', 'leider', 'möglich', 'anderen', 'ganzes', 'vielem', 'vergangenen', 'alles', 'allein', 'mittel', 'denselben', 'heißt', 'keinen', 'ja', 'drin', 'á', 'anderem', 'dann', 'zehnter', 'hinter', 'kaum', 'viertes', 'etwa', 'später', 'ende', 'ein', 'oder', 'unserer', 'so', 'jenem', 'teil', 'erster', 'seitdem', 'zweite', 'er', 'dermaßen', 'großes', 'dieser', 'gegenüber', 'sieben', 'wohl', 'grosses', 'oft', 'solches', 'einiges', 'welchem', 'fünften', 'daneben', 'sechster', 'zehnte', 'weitere', 'allen', 'eine', 'unsere', 'los', 'ausser', 'weiteres', 'jemand', 'siebten', 'na', 'sagte', 'solang', 'ersten', 'tag', 'davon', 'große', 'jetzt', 'noch', 'elf', 'des', 'als', 'vierter', 'nun', 'bisher', 'satt', 'fünf', 'welche', 'nie', 'durch', 'wenig', 'erste', 'vielen', 'wirklich', 'einander', 'davor', 'für', 'jeder', 'kleiner', 'nur', 'zugleich', 'ganze', 'gross', 'achter', 'nach', 'bereits', 'einmaleins', 'kein', 'mich', 'jemanden', 'mit', 'welchen', 'zwei', 'außer', 'um', 'den', 'desselben', 'sechs', 'lange', 'dies', 'jenen', 'demselben', 'solchem', 'allem', 'zehnten', 'sich', 'schon', 'etwas', 'gegen', 'statt', 'siebtes', 'gleich', 'endlich', 'kleinen', 'durften', 'her', 'siebente', 'achtes', 'diejenige', 'oben', 'zunächst', 'eigener', 'gesagt', 'dritten', 'besten', 'dritte', 'jeden', 'weniges', 'wieder', 'a', 'demgemäss', 'dermassen', 'ins', 'jenes', 'also', 'mir', 'ob', 'ehrlich', 'darin', 'einige', 'dritter', 'vier', 'will', 'dahin', 'sechste', 'solcher', 'beim', 'beiden', 'morgen', 'demgemäß', 'musste', 'jahren', 'bekannt', 'was', 'acht', 'uhr', 'vergangene', 'gar', 'immer', 'einer', 'wen', 'danach', 'zusammen', 'vielleicht', 'weiter', 'leicht', 'lang', 'neunten', 'hoch', 'ab', 'von', 'niemanden', 'niemand', 'eigenen', 'nein', 'guter', 'welcher', 'im', 'siebentes', 'wo', 'auf', 'neun', 'dazu', 'zweiten', 'seit', 'je', 'sowie', 'da', 'war', 'einen', 'sei', 'zweiter', 'keiner', 'meine', 'jede', 'tel', 'dort', 'dieselbe', 'rechter', 'beide', 'der', 'dasselbe', 'ohne', 'neuntes', 'dass', 'währenddessen', 'hier', 'recht', 'hat', 'wenige', 'ach', 'neunte', 'ganz', 'unter', 'eben', 'mag', 'manchem', 'einigen', 'das', 'gutes', 'jener', 'überhaupt', 'es', 'hätte', 'zwanzig', 'genug', 'vierten', 'bei', 'ag', 'deinem', 'zum', 'jahr', 'rechte', 'dessen', 'wahr', 'zweites', 'grossen', 'sehr', 'zehntes', 'manchen', 'solche', 'sechstes', 'mancher', 'diese', 'en', 'übrigens', 'auch', 'richtig', 'nichts', 'diesen', 'welches', 'jedermann', 'sagt', 'bis', 'dazwischen', 'neuen', 'sonst', 'vierte', 'entweder', 'grosser', 'erst', 'fünfter', 'gerade', 'zu', 'jedermanns', 'jene', 'am', 'wirst', 'dieses', 'wurde', 'großen', 'während', 'derselben', 'in', 'sechsten', 'dieselben', 'eigenes', 'jahre', 'durchaus', 'viel', 'beispiel', 'rund', 'einiger', 'kleines', 'viele', 'daselbst', 'siebte', 'darüber', 'diesem', 'erstes', 'zurück', 'anders', 'eines', 'manche', 'derjenigen', 'zur', 'rechtes', 'neunter', 'daran', 'irgend', 'daß', 'dabei', 'diejenigen', 'gute', 'weil', 'die', 'dafür', 'natürlich', 'ganzen', 'hast', 'wann', 'aus', 'besser', 'und', 'man', 'fünfte', 'weit', 'einmal', 'drittes', 'ganzer', 'fünftes', 'weiteren', 'alle', 'wenn', 'dadurch', 'gut', 'vor', 'zuerst', 'weniger', 'dem', 'schlecht', 'wessen', 'hin', 'lieber', 'besonders', 'zeit', 'jemandem', 'andern', 'ebenso', 'gemacht', 'darunter', 'tagen', 'uns', 'mehr', 'kurz', 'muss', 'grosse', 'deren', 'wie', 'selbst'}\n"
     ]
    }
   ],
   "source": [
    "# Remove verbs, pronouns and connectors with causal meaning from stopwords\n",
    "spacy_mod.Defaults.stop_words -= {'kam', 'sollte', 'dich', 'achte', 'daraus', 'dir', 'werdet', 'seid', 'unser', 'macht', 'deswegen',\n",
    "                                  'außerdem', 'damit', 'habe', 'können', 'könnt', 'hatte', 'werde', 'andere', 'deiner', 'meines',\n",
    "                                  'niemandem', 'achten', 'dürft', 'rechten', 'machte', 'dahinter', 'sah', 'seinen', 'dementsprechend',\n",
    "                                  'kann', 'muß', 'wäre', 'geworden', 'wegen', 'machen', 'waren', 'dürfen', 'dein', 'mögen', 'würde',\n",
    "                                  'musst', 'magst', 'ihren', 'aber', 'möchte', 'ihr', 'wir', 'allerdings', 'jedem', 'nicht', 'ihres',\n",
    "                                  'kommt', 'gibt', 'infolgedessen', 'mögt', 'doch', 'sollten', 'seine', 'keine', 'wollte', 'ich',\n",
    "                                  'müssen', 'wollten', 'warum', 'ist', 'ihnen', 'mein', 'mochte', 'geht', 'trotzdem', 'gab', 'durfte',\n",
    "                                  'dagegen', 'sie', 'sind', 'wart', 'wer', 'haben', 'du', 'werden', 'eigene', 'ihn', 'seien', 'eigen',\n",
    "                                  'meinen', 'seiner', 'hatten', 'müsst', 'wollen', 'indem', 'wollt', 'gehabt', 'deine',  'denn',\n",
    "                                  'nachdem', 'konnte', 'ihrer', 'seinem', 'gemusst', 'bin', 'währenddem', 'dank', 'willst', 'würden',\n",
    "                                  'gemocht',  'hätten', 'demzufolge', 'seines', 'mussten', 'nahm', 'daher', 'darauf', 'ging', 'mochten',\n",
    "                                  'meinem', 'darum', 'gedurft', 'wurden', 'bist', 'ihrem', 'gehen', 'sein', 'kannst', 'gewollt',\n",
    "                                  'könnte',  'heisst', 'neben', 'meiner', 'euch', 'darfst', 'deshalb', 'konnten', 'ausserdem', 'ihm',\n",
    "                                  'tun', 'gekannt',  'worden', 'habt', 'darf', 'demgegenüber', 'gewesen', 'sollen', 'soll', 'kommen',\n",
    "                                  'tat'}\n",
    "\n",
    "# Inspect spacy stopword list\n",
    "print(spacy_mod.Defaults.stop_words)\n",
    "\n",
    "# Save in object\n",
    "sw_list = spacy_mod.Defaults.stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing\n",
    "def preprocess(doc: str, remove_ent=False):\n",
    "    '''_summary_\n",
    "\n",
    "    Args:\n",
    "        doc (str): String text\n",
    "        remove_ent (bool, optional): If True, removes entities using spaCy. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        doc_preprocessed (list): Preprocessed lower-case corpus with punctuation, non-alphanumeric characters, spaCy stopwords and proper nouns removed.\n",
    "    '''\n",
    "\n",
    "    if remove_ent == True:\n",
    "        doc_no_ent = []\n",
    "        ents = [e.text for e in doc.ents]\n",
    "        for item in doc:\n",
    "            if item.text in ents:\n",
    "                pass\n",
    "            else:\n",
    "                doc_no_ent.append(item)\n",
    "\n",
    "        doc_preprocessed = [token.lemma_.lower() for token in doc_no_ent if\n",
    "                            # token is not punctuation\n",
    "                            token.is_punct == False and\n",
    "                            # token is alphanumeric character\n",
    "                            token.is_alpha == True and\n",
    "                            # token is not stop word\n",
    "                            token.is_stop == False and\n",
    "                            # token is not proper noun\n",
    "                            token.pos_ != 'PROPN']\n",
    "\n",
    "    else:\n",
    "        doc_preprocessed = [token.lemma_.lower() for token in doc if\n",
    "                            # token is not punctuation\n",
    "                            token.is_punct == False and\n",
    "                            # token is alphanumeric character\n",
    "                            token.is_alpha == True and\n",
    "                            # token is not stop word\n",
    "                            token.is_stop == False and\n",
    "                            # token is not proper noun\n",
    "                            token.pos_ != 'PROPN']\n",
    "\n",
    "    return doc_preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2564/2564 [00:04<00:00, 612.68it/s] \n"
     ]
    }
   ],
   "source": [
    "# Preprocess corpus\n",
    "factiva_cleaned = []\n",
    "for doc in tqdm(factiva_spacy): \n",
    "    factiva_cleaned.append(preprocess(doc, remove_ent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stark', 'blutend', 'schnittverletzung', 'alt', 'mann']\n",
      "2564\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# See example\n",
    "print(factiva_cleaned[5][0:5],\n",
    "      len(factiva_cleaned),\n",
    "      type(factiva_cleaned),\n",
    "      sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocation analysis \n",
    "\n",
    "- Collocation across all documents\n",
    "- Collocation across years\n",
    "- Calculate scores (rawfreq + PMI + chisq?) for comparison\n",
    "- Plot comparisons over time: association strength (dot chart) / netowrk  graphs / biplots (using semantic similarity)\n",
    "- Check for collocation strength\n",
    "- Significance testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collocation across all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bigram collocations across all documents\n",
    "finder_bi = nltk.collocations.BigramCollocationFinder.from_documents(\n",
    "    factiva_cleaned)\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "# Store bigram measures in dict for easy access\n",
    "factiva_bigrams = dict(finder_bi.score_ngrams(bigram_measures.raw_freq))\n",
    "\n",
    "# Sort bigram dictionary by value\n",
    "filtered_factiva_bigrams = dict(sorted(factiva_bigrams.items(),\n",
    "                                       key=lambda item: item[1],\n",
    "                                       reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trigram collocations across all documents\n",
    "finder_tri = nltk.collocations.TrigramCollocationFinder.from_documents(\n",
    "    factiva_cleaned)\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "# Store trigram measures in dict\n",
    "factiva_trigrams = dict(finder_tri.score_ngrams(trigram_measures.raw_freq))\n",
    "\n",
    "# Sort trigram dict by value\n",
    "filtered_factiva_trigrams = dict(sorted(factiva_trigrams.items(),\n",
    "                                        key=lambda item: item[1], \n",
    "                                        reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store information in file\n",
    "\n",
    "# Bigrams\n",
    "pp = pprint.PrettyPrinter(indent=2, stream=open(\n",
    "    'outputs/spacy_stopwords/factiva_bigrams_altsw.txt', 'w'), sort_dicts=False)\n",
    "pp.pprint(filtered_factiva_bigrams)\n",
    "\n",
    "# Trigrams\n",
    "pp = pprint.PrettyPrinter(indent=2, stream=open(\n",
    "    'outputs/spacy_stopwords/factiva_trigrams_altsw.txt', 'w'), sort_dicts=False)\n",
    "pp.pprint(filtered_factiva_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('selbstverteidigungsmodus', 'soziologieprofessor', 'grundsatzproblem'),\n",
       " ('gerichtsprozessen', 'strafmilderungen', 'verfahrenseinstellungen'),\n",
       " ('säkulare', 'ursprung', 'hegemonialen'),\n",
       " ('lokaljournalismus', 'datengetriebene', 'investigative'),\n",
       " ('bundestrainerin', 'bundestrainer', 'kapitän'),\n",
       " ('soziologieprofessor', 'grundsatzproblem', 'gleichheit'),\n",
       " ('gemeinnützigen', 'recherchezentrums', 'correctiv'),\n",
       " ('finanzminister', 'berat', 'albayrak'),\n",
       " ('meinungsverschiedenheiten', 'alltägliches', 'fass'),\n",
       " ('existenzrecht', 'beraubt', 'schlussendlich'),\n",
       " ('klinikärzte', 'gynäkologen', 'hausärzte'),\n",
       " ('hauptanteil', 'leichtverletzte', 'ausgemacht'),\n",
       " ('lokalredaktionen', 'umsetzt', 'gemeinnützigen'),\n",
       " ('rechtspopulistischer', 'abgeordneter', 'slowakische'),\n",
       " ('umsetzt', 'gemeinnützigen', 'recherchezentrums'),\n",
       " ('etappensieg', 'kiosk', 'bahnhof'),\n",
       " ('reuben', 'garantien', 'doug'),\n",
       " ('zwängen', 'depressiven', 'verstimmungen'),\n",
       " ('belebten', 'bahnsteig', 'jungfernstieg'),\n",
       " ('erwarb', 'halbautomatisches', 'gewehr'),\n",
       " ('amtierenden', 'finanzminister', 'berat'),\n",
       " ('überstellung', 'ermittlungsrichter', 'vorgeführt'),\n",
       " ('konsumieren', 'übt', 'geschlechtliche'),\n",
       " ('bremischen', 'zentralstelle', 'verwirklichung'),\n",
       " ('halbautomatisches', 'gewehr', 'pistolen'),\n",
       " ('rücksicht', 'untersuche', 'vermerken'),\n",
       " ('militär', 'säkulare', 'ursprung'),\n",
       " ('alltägliches', 'fass', 'überlaufen'),\n",
       " ('erhellen', 'bunte', 'solarlichter'),\n",
       " ('beraubt', 'schlussendlich', 'bedrohe'),\n",
       " ('filmreihe', 'phantastische', 'tierwesen'),\n",
       " ('messerangriff', 'belebten', 'bahnsteig'),\n",
       " ('dunkelblonden', 'kinnlangen', 'haaren'),\n",
       " ('einhaltung', 'männerrechte', 'bewahrung'),\n",
       " ('öfteren', 'zeitverzug', 'anzeigt'),\n",
       " ('örtliche', 'hilfsgruppen', 'paralysiert'),\n",
       " ('bereitschaftsdienst', 'kassenärztlichen', 'vereinigung'),\n",
       " ('spielervereinigung', 'atp', 'tennisprofis'),\n",
       " ('sorgt', 'gerichtsprozessen', 'strafmilderungen'),\n",
       " ('rechtsmediziner', 'spermaspuren', 'hautschuppen'),\n",
       " ('landratsamtes', 'verschiedensten', 'lebensbereiche'),\n",
       " ('buzz', 'feed', 'news'),\n",
       " ('stellwerk', 'bahnhofsvorplatz', 'wusterhausen'),\n",
       " ('unbeabsichtigte', 'konsequenz', 'wirtschaftspolitik'),\n",
       " ('lesbisch', 'schwul', 'bisexuell'),\n",
       " ('erfahrenen', 'psychotherapeuten', 'fachärzten'),\n",
       " ('absolutes', 'no', 'go'),\n",
       " ('first', 'come', 'first'),\n",
       " ('georgische', 'tennisprofi', 'mutmaßlicher'),\n",
       " ('let', 'talk', 'wettbewerb'),\n",
       " ('wehrt', 'öffentlichkeitswirksam', 'tänzen'),\n",
       " ('wirtschaftspolitik', 'staatspräsidenten', 'recep'),\n",
       " ('the', 'british', 'empire'),\n",
       " ('familienverhältnissen', 'berufsgruppen', 'mordean'),\n",
       " ('sozialminister', 'manne', 'lucha'),\n",
       " ('tücken', 'gerichtsfesten', 'medizinischen'),\n",
       " ('depressiven', 'verstimmungen', 'seelischen'),\n",
       " ('unbekleideten', 'körperoberflächen', 'hände'),\n",
       " ('datengetriebene', 'investigative', 'recherchen'),\n",
       " ('fachärzten', 'psychosomatische', 'medizin'),\n",
       " ('räumen', 'frauentreffs', 'jupiterstraße'),\n",
       " ('kaufen', 'erwarb', 'halbautomatisches'),\n",
       " ('talk', 'wettbewerb', 'verständliche'),\n",
       " ('anriefen', 'verdoppelt', 'gesundheitsdienste'),\n",
       " ('hilfsdienste', 'anriefen', 'verdoppelt'),\n",
       " ('hochschule', 'angewandte', 'wissenschaften'),\n",
       " ('historisch', 'ungleichen', 'machtverhältnisse'),\n",
       " ('konsequenz', 'wirtschaftspolitik', 'staatspräsidenten'),\n",
       " ('sonstige', 'sprechzeit', 'montags'),\n",
       " ('mitgliedern', 'präsidentenfamilie', 'älteste'),\n",
       " ('fox', 'news', 'flugzeug'),\n",
       " ('serbe', 'rande', 'finals'),\n",
       " ('leichte', 'abnahme', 'gewaltschutzsachen'),\n",
       " ('schlafentzug', 'typische', 'methode'),\n",
       " ('ängsten', 'zwängen', 'depressiven'),\n",
       " ('filderstadt', 'ostfildern', 'neuhausen'),\n",
       " ('menschenrechtskammer', 'istanbuler', 'anwaltschaft'),\n",
       " ('befund', 'halbwegs', 'fähigen'),\n",
       " ('psychotherapeuten', 'fachärzten', 'psychosomatische'),\n",
       " ('religiöse', 'militär', 'säkulare'),\n",
       " ('oberstleutnant', 'stamminger', 'landespolizeidirektion'),\n",
       " ('symptome', 'bereitschaftsdienst', 'kassenärztlichen'),\n",
       " ('verteidiger', 'nu', 'zerpflückt'),\n",
       " ('übernimmt', 'polizeiaufgaben', 'untersteht'),\n",
       " ('telefonberatung', 'familienzentrum', 'gesprächsbedarf'),\n",
       " ('eingestochen', 'zill', 'tatwaffe'),\n",
       " ('rheinisch', 'bergischen', 'kreises'),\n",
       " ('zielfahndung', 'bundeskriminalamtes', 'lokalisiert'),\n",
       " ('big', 'little', 'lies'),\n",
       " ('seniorentelefon', 'engagement', 'kompass'),\n",
       " ('pressemitteilungen', 'pts', 'jeweiligen'),\n",
       " ('pts', 'jeweiligen', 'aussender'),\n",
       " ('and', 'half', 'men'),\n",
       " ('two', 'and', 'half'),\n",
       " ('untersucht', 'unbekleideten', 'körperoberflächen'),\n",
       " ('schlussendlich', 'bedrohe', 'feminismus'),\n",
       " ('verstimmungen', 'seelischen', 'nöten'),\n",
       " ('madrider', 'oberlandesgerichts', 'verteidigt'),\n",
       " ('bundestrainer', 'kapitän', 'neuer'),\n",
       " ('save', 'the', 'children')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract top 100 bigrams by bmi\n",
    "finder_bi.apply_freq_filter(3)\n",
    "finder_bi.nbest(bigram_measures.pmi, 100)\n",
    "\n",
    "# extract top 100 trigrams by bmi\n",
    "finder_tri.apply_freq_filter(3)\n",
    "finder_tri.nbest(trigram_measures.pmi, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store 100 top bigrams in file\n",
    "with open('outputs/spacy_stopwords/factiva_bigram_pmi_altsw', 'w', encoding='utf-8') as f:\n",
    "    for item in list(finder_bi.nbest(bigram_measures.pmi, 100)):\n",
    "        f.write(f'{item}\\n')\n",
    "\n",
    "# Store 100 top trigrams in file\n",
    "with open('outputs/spacy_stopwords/factiva_trigram_pmi_altsw', 'w', encoding='utf-8') as f:\n",
    "    for item in list(finder_tri.nbest(trigram_measures.pmi, 100)):\n",
    "        f.write(f'{item}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter trigrams / bigrams with certain number of stopwords\n",
    "\n",
    "factiva_trigrams_test = []\n",
    "\n",
    "for doc in list(finder_tri.nbest(trigram_measures.pmi, 100)):\n",
    "    count = 0\n",
    "    for w in doc: \n",
    "        if w in sw_list:\n",
    "            count += 1 \n",
    "    if count <= 1: \n",
    "        factiva_trigrams_test.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factiva_trigrams_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collocation across years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get documents per year\n",
    "\n",
    "factiva_2017 = [x for x in factiva_corpus if x['date'].year == 2017]\n",
    "factiva_2018 = [x for x in factiva_corpus if x['date'].year == 2018]\n",
    "factiva_2019 = [x for x in factiva_corpus if x['date'].year == 2019]\n",
    "factiva_2020 = [x for x in factiva_corpus if x['date'].year == 2020]\n",
    "factiva_2021 = [x for x in factiva_corpus if x['date'].year == 2021]\n",
    "factiva_2022 = [x for x in factiva_corpus if x['date'].year == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frequencies \n",
    "\n",
    "# Turn to pandas df for plot and focus on years \n",
    "df_years = pd.DataFrame.from_dict(factiva_corpus, orient='columns')\n",
    "df_years['date'] = pd.DatetimeIndex(df_years['date']).year\n",
    "plot_years = df_years.groupby(['date'])['title'].count()\n",
    "\n",
    "# Plot as bar chart \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot legend\n",
    "bars = ax.bar(plot_years.index, plot_years)\n",
    "ax.bar_label(bars)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Sum of DA articles')\n",
    "\n",
    "# Plot design\n",
    "ax.set_xticks(plot_years.index)\n",
    "ax.set_yticks(range(200, 800, 200))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess documents for every year 2017 - 2022\n",
    "\n",
    "# Turn to Language object\n",
    "factiva_spacy_2017 = []\n",
    "for doc in tqdm(factiva_2017):\n",
    "    factiva_spacy_2017.append(spacy_mod(doc['body']))\n",
    "factiva_spacy_2018 = []\n",
    "for doc in tqdm(factiva_2018):\n",
    "    factiva_spacy_2018.append(spacy_mod(doc['body']))\n",
    "factiva_spacy_2019 = []\n",
    "for doc in tqdm(factiva_2019):\n",
    "    factiva_spacy_2019.append(spacy_mod(doc['body']))\n",
    "factiva_spacy_2020 = []\n",
    "for doc in tqdm(factiva_2020):\n",
    "    factiva_spacy_2020.append(spacy_mod(doc['body']))\n",
    "factiva_spacy_2021 = []\n",
    "for doc in tqdm(factiva_2021):\n",
    "    factiva_spacy_2021.append(spacy_mod(doc['body']))\n",
    "factiva_spacy_2022 = []\n",
    "for doc in tqdm(factiva_2022):\n",
    "    factiva_spacy_2022.append(spacy_mod(doc['body']))\n",
    "\n",
    "# Preprocess corpus\n",
    "factiva_cleaned_2017 = []\n",
    "for doc in tqdm(factiva_spacy_2017): \n",
    "    factiva_cleaned_2017.append(preprocess(doc, remove_ent=True))\n",
    "factiva_cleaned_2018 = []\n",
    "for doc in tqdm(factiva_spacy_2018): \n",
    "    factiva_cleaned_2018.append(preprocess(doc, remove_ent=True))\n",
    "factiva_cleaned_2019 = []\n",
    "for doc in tqdm(factiva_spacy_2019): \n",
    "    factiva_cleaned_2019.append(preprocess(doc, remove_ent=True))\n",
    "factiva_cleaned_2020 = []\n",
    "for doc in tqdm(factiva_spacy_2020): \n",
    "    factiva_cleaned_2020.append(preprocess(doc, remove_ent=True))\n",
    "factiva_cleaned_2021 = []\n",
    "for doc in tqdm(factiva_spacy_2021): \n",
    "    factiva_cleaned_2021.append(preprocess(doc, remove_ent=True))\n",
    "factiva_cleaned_2022 = []\n",
    "for doc in tqdm(factiva_spacy_2022): \n",
    "    factiva_cleaned_2022.append(preprocess(doc, remove_ent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocation_docs(doc:list, filename:str='', filename_top100:str=''):\n",
    "    '''_summary_\n",
    "\n",
    "    Args:\n",
    "        doc (list): Nested list of strings \n",
    "        filename (str, optional): Filename for list of bigrams. Defaults to '' for no export.\n",
    "        filename_top100 (str, optional): Filename for list of top 100 bigrams by PMI. Defaults to '' for no export.\n",
    "\n",
    "    Returns:\n",
    "        doc_filtered_bigrams (dict): Dictionary of bigrams and scores.\n",
    "    '''\n",
    "    \n",
    "    # Create collocations\n",
    "    finder = nltk.collocations.BigramCollocationFinder.from_documents(doc)\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    doc_bigrams = dict(finder.score_ngrams(bigram_measures.raw_freq))\n",
    "\n",
    "    # Return as dict\n",
    "    doc_filtered_bigrams = dict(sorted(doc_bigrams.items(),\n",
    "                                       key=lambda item: item[1],\n",
    "                                       reverse=True))\n",
    "\n",
    "    # If file name given, write information to file in outputs folder\n",
    "    if not filename:\n",
    "        pass\n",
    "    else:\n",
    "        pp = pprint.PrettyPrinter(indent=2, stream=open(\n",
    "            str('outputs/'+filename+'.txt'), 'w'),\n",
    "            sort_dicts=False)\n",
    "        pp.pprint(doc_filtered_bigrams)\n",
    "    \n",
    "    # If file name given, write top 100 bigrams by PMI to file in outputs folder\n",
    "    if not filename_top100:\n",
    "        pass\n",
    "    else:\n",
    "        finder.apply_freq_filter(3)\n",
    "        with open(str('outputs/'+filename_top100), 'w', encoding='utf-8') as f:\n",
    "            for item in list(finder.nbest(bigram_measures.pmi, 100)):\n",
    "                f.write(f'{item}\\n')\n",
    "\n",
    "        return doc_filtered_bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram collocation analysis for every year\n",
    "\n",
    "collocation_docs(factiva_cleaned_2017, 'factiva_2017', 'factive_2017_top100')\n",
    "collocation_docs(factiva_cleaned_2018, 'factiva_2018', 'factive_2018_top100')\n",
    "collocation_docs(factiva_cleaned_2019, 'factiva_2019', 'factive_2019_top100')\n",
    "collocation_docs(factiva_cleaned_2020, 'factiva_2020', 'factive_2020_top100')\n",
    "collocation_docs(factiva_cleaned_2021, 'factiva_2021', 'factive_2021_top100')\n",
    "collocation_docs(factiva_cleaned_2022, 'factiva_2022', 'factive_2022_top100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate scores for comparison\n",
    "\n",
    "- raw frequencies \n",
    "- PMI \n",
    "- chisquare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
