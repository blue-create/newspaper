{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start\n",
    "\n",
    "- Set working directory\n",
    "- Load modules\n",
    "- Load data\n",
    "- Set datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check working directory\n",
    "import os\n",
    "os.getcwd() # if directory is subfolder, change to home\n",
    "os.chdir('/Users/XXX/newspaper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhuquynh/Library/Python/3.8/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "import datetime as dt\n",
    "import locale\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open(\"data/factiva_data.json\", 'r') as f:\n",
    "    factiva_corpus = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de_DE.UTF-8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change date format\n",
    "locale.setlocale(locale.LC_ALL, 'de_DE.UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing \n",
    "\n",
    "- Convert time data to datetime format \n",
    "- Load spaCy model for tokenization and preprocessing\n",
    "- Remove punctuation, symbols and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string dates to datetime format\n",
    "# Year-Month-Day HH:MM:SS is the default output for string dates\n",
    "\n",
    "for doc in factiva_corpus: \n",
    "    doc['date'] = dt.datetime.strptime(doc['date'], \"%d %B %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2564/2564 [01:43<00:00, 24.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "spacy_mod = spacy.load(\"de_core_news_lg\",\n",
    "                 disable=['ner', 'parser', 'tagger'])\n",
    "\n",
    "# Turn to Language object\n",
    "factiva_spacy = []\n",
    "for doc in tqdm(factiva_corpus):\n",
    "    factiva_spacy.append(spacy_mod(doc['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wart', 'gut', 'heisst', 'so', 'zum', 'bin', 'denselben', 'am', 'hoch', 'indem', 'sein', 'dahinter', 'weitere', 'solcher', 'zweite', 'dieselbe', 'jemanden', 'kein', 'geworden', 'danach', 'gute', 'eigen', 'mein', 'währenddessen', 'als', 'fünfte', 'kleines', 'gemusst', 'darin', 'siebte', 'uhr', 'zu', 'worden', 'habe', 'wessen', 'besten', 'eigenes', 'elf', 'wollt', 'magst', 'wenn', 'jahr', 'manchen', 'besonders', 'deshalb', 'hat', 'konnte', 'jene', 'lang', 'dein', 'der', 'gutes', 'anderem', 'je', 'solchem', 'lange', 'mit', 'oft', 'gesagt', 'niemanden', 'wirklich', 'darfst', 'möglich', 'nichts', 'von', 'anderen', 'ebenso', 'auf', 'gern', 'kleine', 'wurde', 'keinen', 'ihrer', 'neue', 'dieselben', 'jetzt', 'musst', 'zunächst', 'dann', 'gab', 'wie', 'großes', 'schon', 'wem', 'bekannt', 'könnte', 'große', 'nach', 'achter', 'dritten', 'mögen', 'einander', 'dazu', 'kannst', 'ersten', 'möchte', 'dir', 'warum', 'grosser', 'bereits', 'desselben', 'etwas', 'erstes', 'seines', 'rechten', 'sehr', 'besser', 'dadurch', 'diese', 'aller', 'alles', 'denn', 'war', 'um', 'dabei', 'dies', 'vergangenen', 'mancher', 'nachdem', 'konnten', 'müssen', 'sechs', 'achte', 'sich', 'würden', 'bis', 'ihnen', 'allerdings', 'zwischen', 'rechter', 'diejenigen', 'keinem', 'vielleicht', 'jahren', 'drin', 'einer', 'währenddem', 'werdet', 'hier', 'solchen', 'ihn', 'ihres', 'andere', 'weil', 'diesen', 'daneben', 'ganzer', 'davon', 'vom', 'geht', 'eben', 'hätte', 'sondern', 'etwa', 'könnt', 'einem', 'sollten', 'deswegen', 'dessen', 'á', 'will', 'sei', 'derselbe', 'fünfter', 'gekannt', 'gemacht', 'grossen', 'habt', 'sie', 'siebenten', 'durchaus', 'seinen', 'demzufolge', 'viele', 'gehen', 'lieber', 'beiden', 'fünf', 'gross', 'morgen', 'dieses', 'also', 'gewesen', 'ende', 'dort', 'eigene', 'ins', 'natürlich', 'wollte', 'einmaleins', 'zweiten', 'jeder', 'wirst', 'nur', 'ach', 'wird', 'wohl', 'heißt', 'aber', 'zusammen', 'zweiter', 'da', 'durften', 'dermaßen', 'ag', 'mir', 'macht', 'tat', 'kaum', 'deinem', 'gegenüber', 'jede', 'viertes', 'hin', 'andern', 'auch', 'hinter', 'endlich', 'neunten', 'dem', 'darauf', 'vierte', 'eigenen', 'dieser', 'gemocht', 'sollte', 'zehnten', 'demselben', 'sagte', 'es', 'vielem', 'zurück', 'ihrem', 'über', 'was', 'mag', 'niemand', 'übrigens', 'dass', 'ab', 'aus', 'muß', 'sah', 'damit', 'oder', 'dürfen', 'euch', 'mehr', 'musste', 'unserer', 'vierten', 'trotzdem', 'hast', 'mussten', 'zehnter', 'ehrlich', 'einen', 'meine', 'kleinen', 'dagegen', 'den', 'siebtes', 'einiger', 'kommen', 'vierter', 'diesem', 'meinen', 'seiner', 'drei', 'siebente', 'überhaupt', 'einigen', 'muss', 'heute', 'tun', 'gar', 'ein', 'zehn', 'dafür', 'noch', 'machen', 'welchem', 'selbst', 'allgemeinen', 'alle', 'jedoch', 'weniges', 'manches', 'siebten', 'einmal', 'wäre', 'du', 'ihren', 'dasselbe', 'viel', 'kam', 'wurden', 'daraus', 'meiner', 'seien', 'damals', 'dahin', 'gewollt', 'weiter', 'satt', 'waren', 'jener', 'welchen', 'weiteren', 'eine', 'ja', 'mittel', 'sollen', 'derjenige', 'mochte', 'derjenigen', 'sagt', 'immer', 'wir', 'früher', 'grosse', 'tage', 'vielen', 'willst', 'nicht', 'dermassen', 'soll', 'neben', 'seinem', 'jemand', 'bald', 'offen', 'tel', 'diejenige', 'keiner', 'irgend', 'ausser', 'niemandem', 'zehnte', 'recht', 'jeden', 'tag', 'doch', 'fünften', 'allein', 'ausserdem', 'en', 'machte', 'seitdem', 'leider', 'neunte', 'dazwischen', 'hatten', 'demgemäß', 'im', 'beim', 'zweites', 'durfte', 'neun', 'na', 'ihr', 'drittes', 'wo', 'keine', 'dritter', 'jenem', 'zwar', 'ganzes', 'wollten', 'gekonnt', 'achten', 'dritte', 'ich', 'ob', 'zwanzig', 'für', 'daher', 'ganze', 'außerdem', 'einiges', 'würde', 'wen', 'geschweige', 'unter', 'welcher', 'gehabt', 'zwei', 'deren', 'siebter', 'erst', 'sechste', 'solang', 'rechtes', 'an', 'seid', 'teil', 'jedem', 'und', 'allen', 'davor', 'des', 'hatte', 'er', 'hätten', 'außer', 'ist', 'eines', 'neuen', 'sieben', 'neunter', 'durch', 'unser', 'zehntes', 'meines', 'gedurft', 'sechstes', 'wahr', 'sowie', 'tagen', 'allem', 'wer', 'mochten', 'zur', 'können', 'daran', 'richtig', 'welches', 'wollen', 'leicht', 'genug', 'ihre', 'bist', 'uns', 'während', 'statt', 'grosses', 'infolgedessen', 'achtes', 'großen', 'großer', 'vor', 'solches', 'weiteres', 'guter', 'sechster', 'ganz', 'ging', 'jedermanns', 'seit', 'entweder', 'kleiner', 'a', 'zuerst', 'groß', 'sechsten', 'welche', 'sonst', 'los', 'bei', 'einige', 'nahm', 'dich', 'nun', 'deine', 'dasein', 'acht', 'siebentes', 'nein', 'jahre', 'mögt', 'rund', 'wenig', 'vergangene', 'wenigstens', 'schlecht', 'zeit', 'neuntes', 'in', 'müsst', 'daß', 'gibt', 'die', 'meinem', 'oben', 'siebenter', 'manchem', 'jenes', 'bisher', 'darum', 'weit', 'wieder', 'werden', 'zugleich', 'ohne', 'kurz', 'denen', 'derselben', 'ganzen', 'beispiel', 'dürft', 'kann', 'dank', 'fünftes', 'darf', 'anders', 'das', 'wenige', 'darüber', 'her', 'später', 'demgegenüber', 'erste', 'sind', 'gegen', 'darunter', 'gleich', 'erster', 'seine', 'deiner', 'beide', 'mich', 'unsere', 'jenen', 'jedermann', 'kommt', 'haben', 'jemandem', 'rechte', 'demgemäss', 'nie', 'daselbst', 'eigener', 'werde', 'wann', 'solche', 'weniger', 'gerade', 'dementsprechend', 'manche', 'vier', 'ihm', 'man', 'wegen'}\n"
     ]
    }
   ],
   "source": [
    "# Inspect spacy stopword list\n",
    "print(spacy_mod.Defaults.stop_words)\n",
    "\n",
    "# Save in object \n",
    "sw_list = spacy_mod.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing\n",
    "def preprocess(doc: str, remove_ent=False):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        doc (str): String text\n",
    "        remove_ent (bool, optional): If True, removes entities using spaCy. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        doc_preprocessed (list): Preprocessed lower-case corpus with punctuation, non-alphanumeric characters, spaCy stopwords and proper nouns removed.\n",
    "    \"\"\"\n",
    "\n",
    "    if remove_ent == True:\n",
    "        doc_no_ent = []\n",
    "        ents = [e.text for e in doc.ents]\n",
    "        for item in doc:\n",
    "            if item.text in ents:\n",
    "                pass\n",
    "            else:\n",
    "                doc_no_ent.append(item)\n",
    "\n",
    "        doc_preprocessed = [token.lower_ for token in doc_no_ent if\n",
    "                            # token is not punctuation\n",
    "                            token.is_punct == False and\n",
    "                            # token is alphanumeric character\n",
    "                            token.is_alpha == True and\n",
    "                            # token is not stop word\n",
    "                            #token.is_stop == False and\n",
    "                            # token is not proper noun\n",
    "                            token.pos_ != \"PROPN\"]\n",
    "\n",
    "    else:\n",
    "        doc_preprocessed = [token.lower_ for token in doc if\n",
    "                            # token is not punctuation\n",
    "                            token.is_punct == False and\n",
    "                            # token is alphanumeric character\n",
    "                            token.is_alpha == True and\n",
    "                            # token is not stop word\n",
    "                            #token.is_stop == False and\n",
    "                            # token is not proper noun\n",
    "                            token.pos_ != \"PROPN\"]\n",
    "\n",
    "    return doc_preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2564/2564 [00:02<00:00, 1197.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess corpus\n",
    "factiva_cleaned = []\n",
    "for doc in tqdm(factiva_spacy): \n",
    "    factiva_cleaned.append(preprocess(doc, remove_ent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mit', 'stark', 'blutenden', 'und', 'schnittverletzungen']\n",
      "2564\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# See example\n",
    "print(factiva_cleaned[5][0:5],\n",
    "      len(factiva_cleaned),\n",
    "      type(factiva_cleaned),\n",
    "      sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocation analysis \n",
    "\n",
    "- Collocation across all documents\n",
    "- Collocation across years\n",
    "- Calculate scores (rawfreq + PMI + chisq?) for comparison\n",
    "- Plot comparisons over time: association strength (dot chart) / netowrk  graphs / biplots (using semantic similarity)\n",
    "- Check for collocation strength\n",
    "- Significance testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collocation across all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bigram collocations across all documents\n",
    "finder_bi = nltk.collocations.BigramCollocationFinder.from_documents(\n",
    "    factiva_cleaned)\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "# Store bigram measures in dict for easy access\n",
    "factiva_bigrams = dict(finder_bi.score_ngrams(bigram_measures.raw_freq))\n",
    "\n",
    "# Sort bigram dictionary by value\n",
    "filtered_factiva_bigrams = dict(sorted(factiva_bigrams.items(),\n",
    "                                       key=lambda item: item[1],\n",
    "                                       reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trigram collocations across all documents\n",
    "finder_tri = nltk.collocations.TrigramCollocationFinder.from_documents(\n",
    "    factiva_cleaned)\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "# Store trigram measures in dict\n",
    "factiva_trigrams = dict(finder_tri.score_ngrams(trigram_measures.raw_freq))\n",
    "\n",
    "# Sort trigram dict by value\n",
    "filtered_factiva_trigrams = dict(sorted(factiva_trigrams.items(),\n",
    "                                        key=lambda item: item[1], \n",
    "                                        reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store information in file\n",
    "\n",
    "# Bigrams\n",
    "pp = pprint.PrettyPrinter(indent=2, stream=open(\n",
    "    \"outputs/no_stopwords/factiva_bigrams.txt\", 'w'), sort_dicts=False)\n",
    "pp.pprint(filtered_factiva_bigrams)\n",
    "\n",
    "# Trigrams\n",
    "pp = pprint.PrettyPrinter(indent=2, stream=open(\n",
    "    \"outputs/no_stopwords/factiva_trigrams.txt\", 'w'), sort_dicts=False)\n",
    "pp.pprint(filtered_factiva_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 100 bigrams by bmi\n",
    "finder_bi.apply_freq_filter(3)\n",
    "finder_bi.nbest(bigram_measures.pmi, 100)\n",
    "\n",
    "# extract top 100 trigrams by bmi\n",
    "finder_tri.apply_freq_filter(3)\n",
    "finder_tri.nbest(trigram_measures.pmi, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store 100 top bigrams in file\n",
    "with open(\"outputs/no_stopwords/factiva_bigram_pmi\", 'w', encoding='utf-8') as f:\n",
    "    for item in list(finder_bi.nbest(bigram_measures.pmi, 100)):\n",
    "        f.write(f'{item}\\n')\n",
    "\n",
    "# Store 100 top trigrams in file\n",
    "with open(\"outputs/no_stopwords/factiva_trigram_pmi\", 'w', encoding='utf-8') as f:\n",
    "    for item in list(finder_tri.nbest(trigram_measures.pmi, 100)):\n",
    "        f.write(f'{item}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter trigrams / bigrams with certain number of stopwords\n",
    "\n",
    "factiva_trigrams_test = []\n",
    "\n",
    "for doc in list(finder_tri.nbest(trigram_measures.pmi, 100)):\n",
    "    count = 0\n",
    "    for w in doc: \n",
    "        if w in sw_list:\n",
    "            count += 1 \n",
    "    if count <= 1: \n",
    "        factiva_trigrams_test.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factiva_trigrams_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collocation across years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get documents per year\n",
    "\n",
    "factiva_2017 = [x for x in factiva_corpus if x['date'].year == 2017]\n",
    "factiva_2018 = [x for x in factiva_corpus if x['date'].year == 2018]\n",
    "factiva_2019 = [x for x in factiva_corpus if x['date'].year == 2019]\n",
    "factiva_2020 = [x for x in factiva_corpus if x['date'].year == 2020]\n",
    "factiva_2021 = [x for x in factiva_corpus if x['date'].year == 2021]\n",
    "factiva_2022 = [x for x in factiva_corpus if x['date'].year == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frequencies \n",
    "\n",
    "# Turn to pandas df for plot and focus on years \n",
    "df_years = pd.DataFrame.from_dict(factiva_corpus, orient='columns')\n",
    "df_years['date'] = pd.DatetimeIndex(df_years['date']).year\n",
    "plot_years = df_years.groupby(['date'])['title'].count()\n",
    "\n",
    "# Plot as bar chart \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot legend\n",
    "bars = ax.bar(plot_years.index, plot_years)\n",
    "ax.bar_label(bars)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Sum of DA articles')\n",
    "\n",
    "# Plot design\n",
    "ax.set_xticks(plot_years.index)\n",
    "ax.set_yticks(range(200, 800, 200))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess documents for every year 2017 - 2022\n",
    "\n",
    "# Turn to Language object\n",
    "factiva_spacy_2017 = []\n",
    "for doc in tqdm(factiva_2017):\n",
    "    factiva_spacy_2017.append(spacy_mod(doc['body']))\n",
    "factiva_spacy_2018 = []\n",
    "for doc in tqdm(factiva_2018):\n",
    "    factiva_spacy_2018.append(spacy_mod(doc['body']))\n",
    "factiva_spacy_2019 = []\n",
    "for doc in tqdm(factiva_2019):\n",
    "    factiva_spacy_2019.append(spacy_mod(doc['body']))\n",
    "factiva_spacy_2020 = []\n",
    "for doc in tqdm(factiva_2020):\n",
    "    factiva_spacy_2020.append(spacy_mod(doc['body']))\n",
    "factiva_spacy_2021 = []\n",
    "for doc in tqdm(factiva_2021):\n",
    "    factiva_spacy_2021.append(spacy_mod(doc['body']))\n",
    "factiva_spacy_2022 = []\n",
    "for doc in tqdm(factiva_2022):\n",
    "    factiva_spacy_2022.append(spacy_mod(doc['body']))\n",
    "\n",
    "# Preprocess corpus\n",
    "factiva_cleaned_2017 = []\n",
    "for doc in tqdm(factiva_spacy_2017): \n",
    "    factiva_cleaned_2017.append(preprocess(doc, remove_ent=True))\n",
    "factiva_cleaned_2018 = []\n",
    "for doc in tqdm(factiva_spacy_2018): \n",
    "    factiva_cleaned_2018.append(preprocess(doc, remove_ent=True))\n",
    "factiva_cleaned_2019 = []\n",
    "for doc in tqdm(factiva_spacy_2019): \n",
    "    factiva_cleaned_2019.append(preprocess(doc, remove_ent=True))\n",
    "factiva_cleaned_2020 = []\n",
    "for doc in tqdm(factiva_spacy_2020): \n",
    "    factiva_cleaned_2020.append(preprocess(doc, remove_ent=True))\n",
    "factiva_cleaned_2021 = []\n",
    "for doc in tqdm(factiva_spacy_2021): \n",
    "    factiva_cleaned_2021.append(preprocess(doc, remove_ent=True))\n",
    "factiva_cleaned_2022 = []\n",
    "for doc in tqdm(factiva_spacy_2022): \n",
    "    factiva_cleaned_2022.append(preprocess(doc, remove_ent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocation_docs(doc:list, filename:str=\"\", filename_top100:str=\"\"):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        doc (list): Nested list of strings \n",
    "        filename (str, optional): Filename for list of bigrams. Defaults to \"\" for no export.\n",
    "        filename_top100 (str, optional): Filename for list of top 100 bigrams by PMI. Defaults to \"\" for no export.\n",
    "\n",
    "    Returns:\n",
    "        doc_filtered_bigrams (dict): Dictionary of bigrams and scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create collocations\n",
    "    finder = nltk.collocations.BigramCollocationFinder.from_documents(doc)\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    doc_bigrams = dict(finder.score_ngrams(bigram_measures.raw_freq))\n",
    "\n",
    "    # Return as dict\n",
    "    doc_filtered_bigrams = dict(sorted(doc_bigrams.items(),\n",
    "                                       key=lambda item: item[1],\n",
    "                                       reverse=True))\n",
    "\n",
    "    # If file name given, write information to file in outputs folder\n",
    "    if not filename:\n",
    "        pass\n",
    "    else:\n",
    "        pp = pprint.PrettyPrinter(indent=2, stream=open(\n",
    "            str(\"outputs/\"+filename+\".txt\"), 'w'),\n",
    "            sort_dicts=False)\n",
    "        pp.pprint(doc_filtered_bigrams)\n",
    "    \n",
    "    # If file name given, write top 100 bigrams by PMI to file in outputs folder\n",
    "    if not filename_top100:\n",
    "        pass\n",
    "    else:\n",
    "        finder.apply_freq_filter(3)\n",
    "        with open(str(\"outputs/\"+filename_top100), 'w', encoding='utf-8') as f:\n",
    "            for item in list(finder.nbest(bigram_measures.pmi, 100)):\n",
    "                f.write(f'{item}\\n')\n",
    "\n",
    "        return doc_filtered_bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram collocation analysis for every year\n",
    "\n",
    "collocation_docs(factiva_cleaned_2017, \"factiva_2017\", \"factive_2017_top100\")\n",
    "collocation_docs(factiva_cleaned_2018, \"factiva_2018\", \"factive_2018_top100\")\n",
    "collocation_docs(factiva_cleaned_2019, \"factiva_2019\", \"factive_2019_top100\")\n",
    "collocation_docs(factiva_cleaned_2020, \"factiva_2020\", \"factive_2020_top100\")\n",
    "collocation_docs(factiva_cleaned_2021, \"factiva_2021\", \"factive_2021_top100\")\n",
    "collocation_docs(factiva_cleaned_2022, \"factiva_2022\", \"factive_2022_top100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate scores for comparison\n",
    "\n",
    "- raw frequencies \n",
    "- PMI \n",
    "- chisquare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
